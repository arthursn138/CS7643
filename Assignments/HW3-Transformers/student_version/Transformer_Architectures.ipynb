{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SW-QXyz1fdc-"
      },
      "source": [
        "#CS 4464/7643 Deep Learning HW 3\n",
        "Transformers and Language Modeling\n",
        "In this exercise you will implement a Transformer model and several variants such as Encoder Transformers, Decoder Transformers, and Encoder-Decoder transformers.\n",
        "\n",
        "You will then use these as the basis to train a (small) Language Model from scratch on Google Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ErpQkryF1XC",
        "outputId": "6735752a-a69c-4dc5-9874-6c7af579da58"
      },
      "outputs": [],
      "source": [
        "#@title Colab Setup\n",
        "!pip install datasets\n",
        "!pip install tokenizers\n",
        "!pip install sacrebleu\n",
        "!pip install colab-convert\n",
        "!rm -rf gtGPT/\n",
        "!rm -rf gtgpt\n",
        "!git clone https://github.com/Helw150/gtGPT gtGPT\n",
        "!mv gtGPT/gtgpt/ .\n",
        "\n",
        "from gtgpt.utils import set_seed\n",
        "\n",
        "set_seed(3407)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "from gtgpt.utils import set_seed\n",
        "\n",
        "set_seed(3407)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "KhpsJ38gF5Pf"
      },
      "outputs": [],
      "source": [
        "#export\n",
        "import os\n",
        "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"]=\":4096:2\"\n",
        "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"]=\":16:8\"\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "from gtgpt.model import DummyMultiHeadedSelfAttention, DummyBlock, DummyTransformer, DummyEmbedding\n",
        "from gtgpt.utils import set_seed\n",
        "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "torch.set_default_device(DEVICE)\n",
        "\n",
        "# #Do not change, it will break the AutoGrader\n",
        "# setup_block = In[-1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xsNegD_ghJoh"
      },
      "source": [
        "#### Embeddings\n",
        "\n",
        "We will first format our input embeddings similarly to how they are constructed in [BERT](https://arxiv.org/pdf/1810.04805.pdf).\n",
        "\n",
        "Recall from lecture that unlike a RNN, a Transformer does not inherently capture positional information in the forward pass. Because of this, we need to add a signal which encodes the position of each token in its embedding.\n",
        "\n",
        "Your first task is to implement the embedding lookup, including the addition of positional encodings. We have already provided the neccesary parameters inside of `DummyEmbedding`.\n",
        "\n",
        "```python\n",
        "self.vocab_embeddings = nn.Embedding(config.vocab_size, config.n_embd)\n",
        "self.position_embeddings = nn.Embedding(config.block_size, config.n_embd)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "3J4LRVnqF_pT"
      },
      "outputs": [],
      "source": [
        "#export\n",
        "class Embedding(DummyEmbedding):\n",
        "    def forward(self, idx):\n",
        "        \"\"\"\n",
        "        :param idx: intTensor of shape (B,T)\n",
        "        :returns embeddings: floatTensor of shape (B,T,n_embd)\n",
        "        \"\"\"\n",
        "        B, T = idx.size()\n",
        "        embeddings = None\n",
        "        #############################################################################\n",
        "        # TODO:\n",
        "        # Implement the embedding lookup.                                           #\n",
        "        #                                                                           #\n",
        "        # This will take a few lines.                                               #\n",
        "        #############################################################################\n",
        "\n",
        "        # print(idx, idx.size())\n",
        "        # # print(B)\n",
        "        # # print(T)\n",
        "\n",
        "        # # n_embeddings = 3    # From BERT paper\n",
        "\n",
        "        ## From Piazza: idx = word indices; vocab_emb = embeddings for the words;\n",
        "        # pos_emb = embeddings for relative positions\n",
        "\n",
        "        emb_v = self.vocab_embeddings(idx)\n",
        "        # emb_p = self.position_embeddings(idx[B])\n",
        "        # print(emb_v.size())\n",
        "\n",
        "        # # emb_p = torch.zeros_like(emb_v)\n",
        "        # # # print('idx', idx.squeeze().tolist())\n",
        "        # # # list_of_indices = idx.squeeze().tolist()\n",
        "        # # # for i in list_of_indices:\n",
        "        # # for i, word_index in enumerate(idx.squeeze()):\n",
        "        # #     # print(i, word_index)\n",
        "        # #     ii = torch.tensor(i)\n",
        "        # #     # print('ii', ii)\n",
        "        # #     emb_p[:, i, :] = self.position_embeddings(ii)\n",
        "        # #     # print('i=', i, '; emb_p=', emb_p[:, i, :])\n",
        "\n",
        "        # # # print(emb_v)\n",
        "        # # # print(emb_p)\n",
        "        emb_p = self.position_embeddings(torch.arange(T, device=idx.device))[None, :] # Problem solved \n",
        "\n",
        "        embeddings = emb_v + emb_p\n",
        "        # print(embeddings)\n",
        "\n",
        "        ##############################################################################\n",
        "        #                               END OF YOUR CODE                             #\n",
        "        ##############################################################################\n",
        "        return embeddings\n",
        "\n",
        "\n",
        "# #Do not change, it will break the AutoGrader\n",
        "# embedding_def = In[-1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Basic Embedding Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 429
        },
        "id": "bFEN1m6jGeDO",
        "outputId": "8967cca8-d54d-4435-9d8e-e832ceacb61c"
      },
      "outputs": [],
      "source": [
        "#@title Basic Embedding Test\n",
        "\n",
        "def test_embedding():\n",
        "  config = DummyTransformer.get_default_config()\n",
        "  config.vocab_size = 10\n",
        "  config.block_size = 10\n",
        "  config.n_embd = 1\n",
        "  torch.set_default_device(\"cpu\")\n",
        "  set_seed(3047)\n",
        "  embedding = Embedding(config)\n",
        "  embedding.vocab_embeddings.weight = torch.nn.Parameter(torch.arange(0, 10, dtype=torch.float).reshape(10, 1))\n",
        "  embedding.position_embeddings.weight = torch.nn.Parameter(torch.arange(0, 10, dtype=torch.float).reshape(10, 1))\n",
        "  assert torch.allclose(embedding(torch.tensor([[1, 2, 3]])), torch.tensor([1, 3, 5], dtype=torch.float).reshape(1, 3, 1))\n",
        "\n",
        "test_embedding()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_N4g9AtKi1Es"
      },
      "source": [
        "#### 3.2 Multi-head Self-Attention\n",
        "Attention can be computed in matrix-form using the following formula:\n",
        "\n",
        "$Attention(Q, K, V) = softmax(\\frac{QK^T}{\\sqrt{d_k}})V$\n",
        "\n",
        "We want to have multiple self-attention operations. Each of these is called a head with each head applied to some portion of the input.\n",
        "\n",
        "$head_i = Attention(W_Q X_i, W_K X_i, W_V X_i)$\n",
        "\n",
        "Here, we'll use GPT-style Multi-headed Self-Attention which fragments the head into pieces and applies one head to each fragment. The fragments are then concatenated together to reconstruct the transformed input and projected with a feed-forward layer.\n",
        "\n",
        "$MultiHead(Q, K, V) = Concat(head_1, ..., head_h)W^O$\n",
        "\n",
        "Note that while this is \"Multi-head\", all heads can be computed in parallel with a single matrix multiplication. You can find an in-depth description of this in the reference linked in the code.\n",
        "\n",
        "\n",
        "We provide the needed weights in `DummyMultiHeadedSelfAttention`\n",
        "\n",
        "```python\n",
        "# Note that we need this to be true in GPT-style MHA\n",
        "# Knowing this might come in handy :)\n",
        "assert config.n_embd % config.n_head == 0\n",
        "\n",
        "# Note: These could be a single batched linear layer\n",
        "# but we separate them for simplicity of implementation.\n",
        "self.k = nn.Linear(config.n_embd, config.n_embd)\n",
        "self.v = nn.Linear(config.n_embd, config.n_embd)\n",
        "self.q = nn.Linear(config.n_embd, config.n_embd)\n",
        "# output projection\n",
        "self.c_proj = nn.Linear(config.n_embd, config.n_embd)\n",
        "# regularization\n",
        "self.attn_dropout = nn.Dropout(config.attn_pdrop)\n",
        "self.hidden_dropout = nn.Dropout(config.hidden_pdrop)\n",
        "\n",
        "self.n_head = config.n_head\n",
        "self.n_embd = config.n_embd\n",
        "```\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "wJNOQQgaGip4"
      },
      "outputs": [],
      "source": [
        "#export\n",
        "class GenericSelfAttention(DummyMultiHeadedSelfAttention):\n",
        "    def forward(self, x, attention_mask):\n",
        "        \"\"\"\n",
        "        :param x: float Tensor of shape (batch size, sequence length, embedding dimensionality)\n",
        "        :param attention_mask: int Tensor of shape (batch size, 1, sequence length, sequence_length)\n",
        "        :returns y: float Tensor of shape (batch size, sequence length, embedding dimensionality)\n",
        "        \"\"\"\n",
        "        B, T, C = x.size() # batch size, sequence length, embedding dimensionality (n_embd)\n",
        "        y = None\n",
        "\n",
        "        #############################################################################\n",
        "        # TODO:                                                                     #\n",
        "        # Implement multi-headed self-attention in GPT-2 Style                      #\n",
        "        # Use the provided layers initialized in the DummySelfAttention constructor #\n",
        "        # Apply dropout to the attention values after softmax and the final output  #\n",
        "        #                                                                           #\n",
        "        # Reference:                                                                #\n",
        "        # https://jalammar.github.io/illustrated-gpt2/#part-2-illustrated-self-attention\n",
        "        #                                                                           #\n",
        "        # Note: All heads should be computed in parallel using the q,k,v layers     #\n",
        "        #                                                                           #\n",
        "        # For each item in the batch, if attention_mask[b, i, j] = 0,               #\n",
        "        # then you should manually set the attention from token i to j to be -inf   #\n",
        "        # Hint: See torch.masked_fill                                               #\n",
        "        #############################################################################\n",
        "        # print(x, x.size())\n",
        "\n",
        "        ### From Piazza:\n",
        "        ## Don't iterate over n_heads (single matmul should do the job)\n",
        "        ## Should compute the layer norm **after each transformer layer** when iterating over them, rather than only after the final layer.\n",
        "\n",
        "        k = self.k(x)\n",
        "        q = self.q(x)\n",
        "        v = self.v(x)\n",
        "\n",
        "        # print('K:', k.size())   # D_X, D_Q\n",
        "        # print('Q:', q.size())   # D_X, D_Q\n",
        "        # print('V:', v.size())   # D_X, D_V\n",
        "        # # print('Shape K', k.shape)\n",
        "\n",
        "        ## Multihead part: \"splitting\" matrices into different heads (following https://jalammar.github.io/illustrated-gpt2/#part-2-illustrated-self-attention)\n",
        "        # print('Number of heads =', self.n_head)\n",
        "        # print(C / self.n_head)\n",
        "        # k = k.reshape(B, self.n_head, T, C // self.n_head)   # B, H, Dx, Dq (slide notation)\n",
        "        # q = q.reshape(B, self.n_head, T, C // self.n_head)   # B, H, Dx, Dq (slide notation)\n",
        "        # v = v.reshape(B, self.n_head, T, C // self.n_head)   # B, H, Dx, Dv (slide notation)\n",
        "\n",
        "        # print('K:', k.shape)   # D_X, D_Q\n",
        "        # print('Q:', q.shape)   # D_X, D_Q\n",
        "        # print('V:', v.shape)   # D_X, D_V\n",
        "\n",
        "        # ## Alternative way. This way passes next test, but can't have laryernorm to pass\n",
        "        k = k.view(B, T, self.n_head, int(C / self.n_head)).transpose(1, 2) # Ghazal's tip. Ok to use, confirmed in Avinash's OH.\n",
        "        q = q.view(B, T, self.n_head, int(C / self.n_head)).transpose(1, 2) # Ghazal's tip. Ok to use, confirmed in Avinash's OH.\n",
        "        v = v.view(B, T, self.n_head, int(C / self.n_head)).transpose(1, 2) # Ghazal's tip. Ok to use, confirmed in Avinash's OH.\n",
        "\n",
        "        # # # print('Embedding dim:', C)\n",
        "        # # # k.reshape(C, C, -1)\n",
        "\n",
        "        # print('K:', k.size())   # H, Dx, Dq (slide notation)\n",
        "        # print('Q:', q.size())   # H, Dx, Dq (slide notation)\n",
        "        # print('V:', v.size())   # H, Dx, Dv (slide notation)\n",
        "\n",
        "        similarities = torch.matmul(q, torch.transpose(k, 2, 3)) / torch.sqrt(torch.tensor(k.shape[3])) # Normalized by Dq (slides notation)\n",
        "        # print(similarities) # IF DOESN'T WORK, TRY TORCH.BMM<>TORCH.MATMUL<> @\n",
        "        # mask1 = torch.where(attention_mask == 0, -float('inf'), attention_mask)\n",
        "        # print('torch.where:', mask1)\n",
        "        # mask = attention_mask.masked_fill(attention_mask == 0, float('-inf'))\n",
        "        # # print('masked_fill:', mask2)\n",
        "        masked_sim = similarities.masked_fill(attention_mask == 0, float('-inf'))\n",
        "        # # # print('similarities', similarities)\n",
        "        # # # print('masked_sim', masked_sim)\n",
        "        # # # print('elementwise multiplication', similarities * mask)\n",
        "        # # # # similarities = similarities * mask\n",
        "\n",
        "        self.softmax = nn.Softmax(dim=3)\n",
        "        softmax = self.softmax(masked_sim)\n",
        "        # print(softmax)\n",
        "        first_dropout = self.attn_dropout(softmax)\n",
        "        # print(first_dropout)\n",
        "\n",
        "        att = torch.matmul(first_dropout, v)\n",
        "        # # # print('Before summing', att)\n",
        "        # # # print(att.shape)\n",
        "        # # # summed = torch.sum(att, dim=1)\n",
        "        # # # print('Checking if summed over the correct dimension', summed)\n",
        "\n",
        "        ## Concatenating heads' outputs and performing projections\n",
        "        # reshaping = att.transpose(1, 2)\n",
        "        # concat = att.reshape(B, T, C)   # Looks like it is reshaping the way I want\n",
        "        \n",
        "        # # # concat = torch.zeros_like(x)\n",
        "        # # # for i in range(self.n_head):\n",
        "        # # #     a = att[:, i, :, :]\n",
        "        # # #     torch.cat((a, a))\n",
        "        # # #     # concat[:, :, i] = \n",
        "\n",
        "        # # # concat = att.contiguous().view(B, T, C) # This way passes next test, but can't have laryernorm\n",
        "        concat = att.transpose(1, 2).contiguous().view(B, T, C) # Matches Ghazal's tips. This way passes next test. Confirmed in Avinash's OH.\n",
        "        # # # print(concat)\n",
        "        projected = self.c_proj(concat)\n",
        "        # print(projected)\n",
        "\n",
        "        y = self.hidden_dropout(projected)\n",
        "        # print(second_dropout)\n",
        "        # print(attention_mask)\n",
        "\n",
        "        # self.normalization = nn.LayerNorm(C)\n",
        "        # y = self.normalization(y)   #.detach().float()\n",
        "        \n",
        "        # print(y)\n",
        "        # print(type(y))\n",
        "\n",
        "        ##############################################################################\n",
        "        #                               END OF YOUR CODE                             #\n",
        "        ##############################################################################\n",
        "\n",
        "        return y\n",
        "\n",
        "# #Do not change, it will break the AutoGrader\n",
        "# mha_def = In[-1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Test Multi-Headed Attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "cellView": "form",
        "id": "TOONbP93GrGT"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Success 1\n",
            "Success 2\n"
          ]
        }
      ],
      "source": [
        "#@title Test Multi-Headed Attention\n",
        "\n",
        "def test_mha():\n",
        "  config = DummyTransformer.get_default_config()\n",
        "  config.vocab_size = 10\n",
        "  config.block_size = 10\n",
        "  config.n_embd = 4\n",
        "  config.n_head = 2\n",
        "  config.hidden_pdrop = 0.25\n",
        "  config.attn_pdrop = 0.1\n",
        "  set_seed(3407)\n",
        "  torch.set_default_device(\"cpu\")\n",
        "  attn = GenericSelfAttention(config)\n",
        "  attn.q.weight = torch.nn.Parameter(torch.eye(2, 2).repeat(2, 2).flip(0))\n",
        "  attn.q.bias = torch.nn.Parameter(torch.zeros(4))\n",
        "  attn.k.weight = torch.nn.Parameter(torch.eye(2, 2).repeat(2, 2))\n",
        "  attn.k.bias = torch.nn.Parameter(torch.zeros(4))\n",
        "  attn.v.weight = torch.nn.Parameter(torch.eye(4, 4))\n",
        "  attn.v.bias = torch.nn.Parameter(torch.zeros(4))\n",
        "  attn.c_proj.weight = torch.nn.Parameter(torch.eye(4, 4))\n",
        "  attn.c_proj.bias = torch.nn.Parameter(torch.zeros(4))\n",
        "  embeddings = torch.tensor([[[1, 2, 3, 4] ,[4, 3, 2, 1]]], dtype=torch.float)\n",
        "  mask = torch.ones(1, 2, 2)\n",
        "  assert torch.allclose(attn(embeddings, mask), torch.tensor([[[5.6779, 0, 0, 0], [0, 3.0456, 4.3618, 5.6779]]], dtype=torch.float), atol=1e-3, rtol=1)\n",
        "  print(\"Success 1\")\n",
        "\n",
        "test_mha()\n",
        "\n",
        "def test_mha_mask():\n",
        "  config = DummyTransformer.get_default_config()\n",
        "  config.vocab_size = 10\n",
        "  config.block_size = 10\n",
        "  config.n_embd = 4\n",
        "  config.n_head = 2\n",
        "  config.hidden_pdrop = 0.0\n",
        "  config.attn_pdrop = 0.0\n",
        "  set_seed(3407)\n",
        "  torch.set_default_device(\"cpu\")\n",
        "  attn = GenericSelfAttention(config)\n",
        "  attn.v.weight = torch.nn.Parameter(torch.eye(4, 4))\n",
        "  attn.v.bias = torch.nn.Parameter(torch.zeros(4))\n",
        "  attn.c_proj.weight = torch.nn.Parameter(torch.eye(4, 4))\n",
        "  attn.c_proj.bias = torch.nn.Parameter(torch.zeros(4))\n",
        "  embeddings = torch.tensor([[[1, 2, 3, 4] ,[4, 3, 2, 1]]], dtype=torch.float)\n",
        "  mask = torch.zeros(1, 2, 2)\n",
        "  mask[0, 0, 0] = 1\n",
        "  mask[0, 1, 1] = 1\n",
        "  assert torch.allclose(attn(embeddings, mask), torch.tensor([[[1, 2, 3, 4], [4, 3, 2, 1]]], dtype=torch.float), atol=1e-4)\n",
        "  print(\"Success 2\")\n",
        "\n",
        "test_mha_mask()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Now, we can very simply create a single layer transformer block!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "V-LkiiMDG0iN"
      },
      "outputs": [],
      "source": [
        "#export\n",
        "#@title Now, we can very simply create a single layer transformer block!\n",
        "class TransformerBlock(DummyBlock):\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config, GenericSelfAttention)\n",
        "\n",
        "    # A Basic Transformer Block with Attention followed by an MLP\n",
        "    # note the layer norms and residual information preserved at each step.\n",
        "    def forward(self, x, attention_mask):\n",
        "        x = x + self.attn(self.ln_1(x), attention_mask)\n",
        "        x = x + self.mlpf(self.ln_2(x))\n",
        "        return x\n",
        "\n",
        "# #Do not change, it will break the AutoGrader\n",
        "# block_def = In[-1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0XlolMIhnfBa"
      },
      "source": [
        "#### Putting it all together\n",
        "\n",
        "Using our Embedding Layer, the above Transformer Block using our Multi-head attention, and a simple classification head we have all the pieces we need for a Transformer language model.\n",
        "\n",
        "For the forward pass, you'll want to first embed our inputs, apply each transformer layer sequentially, and finally get logits for each possible output word using a classification layer (often called a language modeling head).\n",
        "\n",
        "If an argument is passed to `hidden_cache`, you should prepend it to your input embeddings and pass it alongside the embeddings for the rest of the model. This will allow use to use this structure in Encoder-Decoder architectures later, but also allows passing vectors from any other neural network (such as a computer vision model or an audio model to enable multi-modal understanding). You can find a rich description of how these pieces come together [here](https://jalammar.github.io/illustrated-transformer/).\n",
        "\n",
        "All the parameters you'll need come from `DummyTransformer` and the code blocks above your code section.\n",
        "\n",
        "```python\n",
        "self.transformer = nn.ModuleDict(\n",
        "    dict(\n",
        "        embedding=embedding(config),\n",
        "        h=nn.ModuleList(\n",
        "            [block(config) for _ in range(config.n_layer)]\n",
        "        ),\n",
        "        ln_f=nn.LayerNorm(config.n_embd),\n",
        "    )\n",
        ")\n",
        "self.lm_head = nn.Linear(config.n_embd, config.vocab_size, bias=False)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "UJCBDuLzncKd"
      },
      "outputs": [],
      "source": [
        "#export\n",
        "class GenericTransformer(DummyTransformer):\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config, TransformerBlock, Embedding)\n",
        "        self.block_size = config.block_size # Maximum Number of Tokens which can be encoded at once\n",
        "        self.vocab_size = config.vocab_size\n",
        "\n",
        "    def get_attention_mask(self, num_tokens):\n",
        "        \"\"\"\n",
        "        Dummy For now, we will see how we use this later!\n",
        "        \"\"\"\n",
        "        B = num_tokens.shape[0]\n",
        "        return torch.ones((B, self.block_size, self.block_size))[:, :num_tokens.max().item(), :num_tokens.max().item()]\n",
        "\n",
        "    def forward(self, idx, targets=None, hidden_cache=None, return_hidden=False):\n",
        "        \"\"\"\n",
        "        :param idx: int Tensor of shape (B,T)\n",
        "        :param hidden_cache: float Tensor of shape (B,P_T,n_embd)\n",
        "        :param targets: int Tensor of shape (B,T_T)\n",
        "        :param return_hidden: bool\n",
        "        (if return_hidden = None)\n",
        "        :returns x: float Tensor of shape (B,T,n_embd)\n",
        "        (else)\n",
        "        :returns logits: float Tensor of shape (B, T, vocab_size)\n",
        "        :returns loss: float Tensor of shape (B) or None\n",
        "        \"\"\"\n",
        "        num_tokens = (idx != -1).type(torch.int).sum(dim=1)\n",
        "        if hidden_cache is not None:\n",
        "          num_tokens = num_tokens + hidden_cache.shape[1]\n",
        "        idx = idx.masked_fill(idx == -1, int(0)).type(torch.int)[:, :num_tokens.max().item()]\n",
        "        if targets is not None:\n",
        "          targets = targets[:, :num_tokens.max().item()]\n",
        "        attention_mask = self.get_attention_mask(num_tokens)\n",
        "        #############################################################################\n",
        "        # TODO:                                                                     #\n",
        "        # Put all the modules of a Transformer together for inference               #\n",
        "        #                                                                           #\n",
        "        # If hidden_cache exists,                                                   #\n",
        "        # then the Transformer inputs should be concatenated in the token dimension #\n",
        "        # First) All Embeddings from Hidden Cache                                   #\n",
        "        # Next)  All Embeddings of tokens from idx.                                 #\n",
        "        #                                                                           #\n",
        "        # All the modules you'll need are listed here:                              #\n",
        "        #                                                                           #\n",
        "        # Note: You can iterate through a nn.ModuleList using a standard for loop.  #\n",
        "        #                                                                           #\n",
        "        # This will take a few lines!                                               #\n",
        "        ##############################################################################\n",
        "\n",
        "        emb = self.transformer['embedding'](idx) # Embed inputs \n",
        "\n",
        "        # print(emb.shape) # Shape 1, 5, 4 (B, T, n_emb) \n",
        "\n",
        "        if hidden_cache is not None: \n",
        "          emb = torch.cat((hidden_cache, emb), dim=1) \n",
        "          # idx = torch.cat((hidden_cache['tokens'], idx), dim=1) \n",
        "\n",
        "        # # print(len(attention_mask.shape))\n",
        "        # if len(attention_mask.shape) == 3: \n",
        "        #   B, T, T2 = attention_mask.shape \n",
        "        #   attention_mask = attention_mask.reshape(B, 1, T, T2) # From Piazza, reshaping here is needed (if it doesn't work, change it to 3D in GenericSelfAttention) \n",
        "\n",
        "        # print(self.transformer['h']) # There already are some Layernorms going on \n",
        "        # transf = self.transformer['h'](idx) # Apply each transformer layer sequentially \n",
        "\n",
        "        x = emb\n",
        "        for i in self.transformer['h']: # Apply each transformer layer sequentially \n",
        "          # print(i) # There are some layernorms, but not at the end of each transformer block \n",
        "          x = i(x, attention_mask) \n",
        "          norm = self.transformer['ln_f'](x) \n",
        "          x = norm # Ensures normalizations after each block/iteration\n",
        "\n",
        "        logits = self.lm_head(x)\n",
        "\n",
        "        # x = torch.tensor(1)\n",
        "        # logits = torch.tensor(1)\n",
        "\n",
        "\n",
        "        ### From Piazza: \n",
        "        ## Should compute the layer norm **after each transformer layer** when iterating over them, rather than only after the final layer. \n",
        "        ## From Manav on Piazza: \"Now after the model generates the token, we normalize the logits to get probability values and decide which one to sample.\" \n",
        "        # self.normalization = nn.LayerNorm(C) \n",
        "        # y = self.normalization(y) #.detach().float()\n",
        "\n",
        "        ##############################################################################\n",
        "        #                               END OF YOUR CODE                             #\n",
        "        ##############################################################################\n",
        "        if return_hidden:\n",
        "            return x\n",
        "\n",
        "        # if we are given some desired targets also calculate the loss\n",
        "        loss = None\n",
        "        if targets is not None:\n",
        "            s_logits = logits\n",
        "            if hidden_cache is not None:\n",
        "              s_logits = logits[:, hidden_cache.shape[1]-1:-1].contiguous()\n",
        "              #print(logits[-1].argmax(dim=1))\n",
        "            loss = F.cross_entropy(\n",
        "                s_logits.reshape(-1, self.vocab_size), targets.reshape(-1), ignore_index=-1\n",
        "            )\n",
        "\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "# #Do not change, it will break the AutoGrader\n",
        "# transformer_def = In[-1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Test Full Transformer Forward Pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "cellView": "form",
        "id": "GvahgUP5G04t"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "number of parameters: 0.00M\n",
            "Success 1\n",
            "number of parameters: 0.00M\n",
            "Success 2\n",
            "number of parameters: 0.00M\n",
            "Success 3\n"
          ]
        }
      ],
      "source": [
        "#@title Test Full Transformer Forward Pass\n",
        "\n",
        "def test_transformer():\n",
        "  config = DummyTransformer.get_default_config()\n",
        "  config.vocab_size = 10\n",
        "  config.block_size = 10\n",
        "  config.n_layer = 2\n",
        "  config.n_embd = 4\n",
        "  config.n_head = 2\n",
        "  torch.set_default_device(\"cpu\")\n",
        "  set_seed(3407)\n",
        "  transformer = GenericTransformer(config)\n",
        "  idx = torch.tensor([[1, 2, 3, 4, 5, -1, -1, -1, -1, -1]], dtype=torch.long)\n",
        "  s = F.softmax(transformer(idx)[0][0, 0], dim=0)\n",
        "  assert torch.allclose(s, torch.tensor([0.1034, 0.0960, 0.1019, 0.1022, 0.1003, 0.1040, 0.0983, 0.1072, 0.0958, 0.0910], dtype=torch.float), atol=1e-5, rtol=1)\n",
        "  print(\"Success 1\")\n",
        "\n",
        "def test_transformer_loss():\n",
        "  config = DummyTransformer.get_default_config()\n",
        "  config.vocab_size = 10\n",
        "  config.block_size = 10\n",
        "  config.n_layer = 2\n",
        "  config.n_embd = 4\n",
        "  config.n_head = 2\n",
        "  torch.set_default_device(\"cpu\")\n",
        "  set_seed(3407)\n",
        "  transformer = GenericTransformer(config)\n",
        "  idx = torch.tensor([[1, 2, 3, 4, 5, -1, -1, -1, -1, -1]], dtype=torch.long)\n",
        "  target = torch.arange(5).reshape(1, 5)\n",
        "  assert torch.allclose(transformer(idx, targets=target)[1], torch.tensor(2.2973))\n",
        "  print(\"Success 2\")\n",
        "\n",
        "def test_transformer_hidden():\n",
        "  config = DummyTransformer.get_default_config()\n",
        "  config.vocab_size = 10\n",
        "  config.block_size = 10\n",
        "  config.n_layer = 2\n",
        "  config.n_embd = 4\n",
        "  config.n_head = 2\n",
        "  torch.set_default_device(\"cpu\")\n",
        "  set_seed(3407)\n",
        "  transformer = GenericTransformer(config)\n",
        "  idx = torch.tensor([[1, 2, 3, 4, 5, -1, -1, -1, -1, -1]], dtype=torch.long)\n",
        "  target = torch.arange(5).reshape(1, 5)\n",
        "  hidden = transformer(idx, targets=target, return_hidden=True)\n",
        "  assert torch.allclose(hidden[0, 0], torch.tensor([1.4417, -1.3564,  0.1549, -0.2401]), atol=1e-4)\n",
        "  print(\"Success 3\")\n",
        "\n",
        "test_transformer()\n",
        "test_transformer_loss()\n",
        "test_transformer_hidden()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TYNuYWMn0iaS"
      },
      "source": [
        "#### Implement an Encoder Transformer\n",
        "\n",
        "Encoders, like the BERT model you learned about in lecture, utilize bi-directional attention. This means that in the sequence \"A B C\", the representation for token \"B\" will be influenced by tokens A *and* C. When all tokens can attend to all other tokens, the attention_mask is just a matrix of ones.\n",
        "\n",
        "However, since sentences come in a wide range of lengths, we need a way to batch sequences of different lengths together in order to maximize our GPU throughput. The most common way of doing this is called \"Padding\". When you pad an input, you add additional \"pad\" tokens to make it the same length as the longest sequence in a batch. For example, if we wanted to batch \"A B C\" and \"A B C D\" together, we would add a \"pad\" token to \"A B C\". Our resulting batch would be \\[\"A B C \\<pad\\>\", \"A B C D\"\\].\n",
        "\n",
        "Since these pad tokens are meaningless, we want to avoid having them affect our results. To do this, we remove them from the attention mask for that element in the batch. Below, you'll write a function to create such an attention mask for padded sequences given a tensor which contains the number of valid leading tokens for each batch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "VF8grwOtG-gs"
      },
      "outputs": [],
      "source": [
        "#export\n",
        "class Encoder(GenericTransformer):\n",
        "    \"\"\"Encoder Style Transformer with Bidirectional Attention\"\"\"\n",
        "    def get_attention_mask(self, num_tokens):\n",
        "        \"\"\"\n",
        "        :param num_tokens: int Tensor of shape (batch size)\n",
        "        :returns attention_mask: int tensor of shape (batch_size, 1, max_tokens, max_tokens)\n",
        "        \"\"\"\n",
        "        B = num_tokens.shape[0]\n",
        "        max_tokens = min(self.block_size, num_tokens.max().item())\n",
        "        ##############################################################################\n",
        "        # TODO:                                                                      #\n",
        "        # Implement a padding mask function.                                         #\n",
        "        # This allows batching sequences of different lengths.                       #\n",
        "        #                                                                            #\n",
        "        # For example, for any row attention_mask[b, i] the following should be true:#\n",
        "        #               For j < num_tokens[b], attention_mask[b, i, j] = 1          #\n",
        "        #               For j >= num_tokens[b],  attention_mask[b, i, j] = 0         #\n",
        "        #                                                                            #\n",
        "        # Reference:https://huggingface.co/docs/transformers/glossary#attention-mask #                                                                #\n",
        "        #                                                                            #\n",
        "        # This should be a 1-3 line function.                                        #\n",
        "        ##############################################################################\n",
        "        \n",
        "        # Create attention mask\n",
        "        attention_mask = torch.ones((B, max_tokens, max_tokens))\n",
        "        # print(max_tokens)\n",
        "\n",
        "        # Zeros where there is too many tokens\n",
        "        # print(num_tokens)   # [5, 6]\n",
        "        for i in range(B):\n",
        "            # print(num_tokens[i])\n",
        "            if max_tokens > num_tokens[i]:\n",
        "                diff = (max_tokens - num_tokens[i]).item()\n",
        "                attention_mask[i, :, -diff:] = 0\n",
        "        \n",
        "        # print(attention_mask)\n",
        "\n",
        "        ##############################################################################\n",
        "        #                               END OF YOUR CODE                             #\n",
        "        ##############################################################################\n",
        "        return attention_mask.reshape(B, 1, max_tokens, max_tokens)\n",
        "\n",
        "# #Do not change, it will break the AutoGrader\n",
        "# encoder_def = In[-1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Test Encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "cellView": "form",
        "id": "pXGGTqi4G-6i"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "number of parameters: 0.00M\n"
          ]
        }
      ],
      "source": [
        "#@title Test Encoder\n",
        "\n",
        "def test_encoder():\n",
        "  config = DummyTransformer.get_default_config()\n",
        "  config.vocab_size = 10\n",
        "  config.block_size = 10\n",
        "  config.n_layer = 2\n",
        "  config.n_embd = 4\n",
        "  config.n_head = 2\n",
        "  torch.set_default_device(\"cpu\")\n",
        "  set_seed(3407)\n",
        "  transformer = Encoder(config)\n",
        "  mask = transformer.get_attention_mask(torch.tensor([5, 6]))\n",
        "  assert mask[0, :, 0].sum() == 5\n",
        "  assert mask[1, :, 0].sum() == 6\n",
        "\n",
        "\n",
        "test_encoder()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wfA1ktrT2l0a"
      },
      "source": [
        "#### Implement an Decoder Transformer\n",
        "\n",
        "Unlike Encoders, Decoders are a \"causal\" model, meaning that each prediction is only influenced by the tokens which came earlier than it in the input. While \"Encoders\" and \"Decoders\" are often discussed as different types of models, the only core difference is the attention mask used.\n",
        "\n",
        "For decoders, we want the attention mask for each token to only include the previous tokens in the sequence. Despite being functionally very different models, a \"Decoder\" can be implemented with just a one line change of the \"Encoder\" attention mask. You'll implement this below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "je6nfibPHGPr"
      },
      "outputs": [],
      "source": [
        "#export\n",
        "class Decoder(Encoder):\n",
        "    \"\"\"Decoder Style model with a Causal Attention Mask\"\"\"\n",
        "\n",
        "    def get_attention_mask(self, num_tokens):\n",
        "        \"\"\"\n",
        "        :param num_tokens: int Tensor of shape (batch size)\n",
        "        :returns attention_mask: int tensor of shape (batch_size, 1, block_size, block_size)\n",
        "        \"\"\"\n",
        "        full_attention_mask = super().get_attention_mask(num_tokens)\n",
        "        ##############################################################################\n",
        "        # TODO:                                                                      #\n",
        "        # Modify the output of the full encoder mask to create a \"causal\" mask       #\n",
        "        # such that tokens only attend to tokens which occured earlier in the input. #\n",
        "        #                                                                            #\n",
        "        # For example, for any row attention_mask[b, i} the following should be true:#\n",
        "        #               For j <= i, attention_mask[b, i, j] = 1                      #\n",
        "        #               For j > i,  attention_mask[b, i, j] = 0                      #\n",
        "        #                                                                            #\n",
        "        # This should be a one line function which modifies the full attention_mask  #\n",
        "        ##############################################################################\n",
        "        \n",
        "        # Call/create attention mask\n",
        "        attention_mask = full_attention_mask\n",
        "        for i in range(attention_mask.shape[2]):\n",
        "            for j in range(attention_mask.shape[3]):\n",
        "                if j > i:\n",
        "                    attention_mask[:, :, i, j:] = 0\n",
        "\n",
        "        ##############################################################################\n",
        "        #                               END OF YOUR CODE                             #\n",
        "        ##############################################################################\n",
        "        return attention_mask\n",
        "\n",
        "# #Do not change, it will break the AutoGrader\n",
        "# decoder_def = In[-1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Test Decoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "cellView": "form",
        "id": "nyg5zzmc_8y0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "number of parameters: 0.00M\n"
          ]
        }
      ],
      "source": [
        "#@title Test Decoder\n",
        "\n",
        "def test_decoder():\n",
        "  config = DummyTransformer.get_default_config()\n",
        "  config.vocab_size = 10\n",
        "  config.block_size = 10\n",
        "  config.n_layer = 2\n",
        "  config.n_embd = 4\n",
        "  config.n_head = 2\n",
        "  torch.set_default_device(\"cpu\")\n",
        "  set_seed(3407)\n",
        "  transformer = Decoder(config)\n",
        "  mask = transformer.get_attention_mask(torch.tensor([[5], [6]]))\n",
        "  for i in range(5):\n",
        "    assert mask[0, :, i].sum() == i+1\n",
        "  assert mask[0, :, 5].sum() == 5\n",
        "  for i in range(6):\n",
        "    assert mask[1, :, i].sum() == i+1\n",
        "\n",
        "test_decoder()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UABwUKI93c_A"
      },
      "source": [
        "#### Use your model to generate!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "JEbiacH3JUF8"
      },
      "outputs": [],
      "source": [
        "#export\n",
        "def generate(model, idx, max_new_tokens, temperature=1.0):\n",
        "    \"\"\"\n",
        "    :param idx: int Tensor of shape (B, T)\n",
        "    :param max_new_tokens: int\n",
        "    :param temperature: Float\n",
        "    :returns idx: int Tensor of shape (B, T+max_new_tokens)\n",
        "    \"\"\"\n",
        "    ##############################################################################\n",
        "    # TODO:                                                                      #\n",
        "    # Sample from your model max_new_tokens times                                #\n",
        "    # You should feed the predictions back into the model each time              #\n",
        "    #                                                                            #\n",
        "    # Adjust the probability distribution to be more or less greedy using        #\n",
        "    # the temperature parameter                                                  #\n",
        "    #                                                                            #\n",
        "    # Reference: https://huggingface.co/blog/how-to-generate#sampling            #\n",
        "    # Temperature Reference:                                                     #\n",
        "    # https://web.stanford.edu/class/cs224n/slides/cs224n-2023-lecture10-nlg.pdf#page=34 #\n",
        "    ##############################################################################\n",
        "    \n",
        "    # print(idx.shape)\n",
        "    B, T = idx.shape\n",
        "    # print(B, T)\n",
        "    # print(max_new_tokens) # 6\n",
        "\n",
        "    ### From Krishanu's OH:\n",
        "    ## logits -> temp red -> softmax -> multinomial(?) -> concat -> repeat using only the last array\n",
        "    ## model should be a tuple of logits and loss\n",
        "    for _ in range(int(max_new_tokens)):\n",
        "        sample = model(idx)[0][:, -1, :]  #.reshape(B, -1)\n",
        "        # print(sample)\n",
        "        temp_reduced = sample / temperature # https://web.stanford.edu/class/cs224n/slides/cs224n-2023-lecture10-nlg.pdf#page=34\n",
        "        # print(temp_reduced)\n",
        "        softmax = F.softmax(temp_reduced, dim=1)\n",
        "        # print(softmax)\n",
        "        # test = torch.tensor([7,8,9], dtype=torch.float)\n",
        "        choice_idx = torch.multinomial(softmax, num_samples=1)\n",
        "        # print(choice_idx)\n",
        "        # print(softmax.shape)\n",
        "        # print((softmax[:, choice_idx]).reshape(1,1).shape, 'and', idx.shape)\n",
        "        # print(softmax[:, choice_idx].reshape(1,1))\n",
        "        idx = torch.cat((idx, choice_idx), dim=1)\n",
        "        # print(idx)\n",
        "    \n",
        "    # print(idx.shape)\n",
        "\n",
        "    ##############################################################################\n",
        "    #                               END OF YOUR CODE                             #\n",
        "    ##############################################################################\n",
        "    return idx\n",
        "\n",
        "# #Do not change, it will break the AutoGrader\n",
        "# generate_def = In[-1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Test Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "cellView": "form",
        "id": "UR1Zn12LanRo"
      },
      "outputs": [],
      "source": [
        "#@title Test Generation\n",
        "\n",
        "def test_generate():\n",
        "    def dumb_model(idx):\n",
        "      l = torch.zeros(1, 1, 10)\n",
        "      l[0, 0, 0] = 100\n",
        "      l[0, 0, 5] = 90\n",
        "      return l.roll(int(idx[0, -1].item())+1), None\n",
        "    torch.set_default_device(\"cpu\")\n",
        "    set_seed(3047)\n",
        "    assert torch.allclose(generate(dumb_model, torch.tensor([[0]]), 6), torch.tensor([0,1,2,3,4,5,6]))\n",
        "    temp_gen_1 = generate(dumb_model, torch.tensor([[0]]), 6, temperature=10)\n",
        "    assert torch.allclose(temp_gen_1, torch.tensor([[0, 6, 2, 3, 4, 5, 6]]))\n",
        "\n",
        "test_generate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kYnbvnKI3gnF"
      },
      "source": [
        "#### Implement an Encoder Decoder Transformer\n",
        "\n",
        "Now, we'll put together our Encoder and Decoder models. This combination of the two architectures allows us to maximize the signal we can draw from the input using a bi-directional encoder, while generating language using a causal decoder.\n",
        "\n",
        "Below, you'll combine your Encoder and Decoder classes in a forward function making use of the `return_hidden` and `hidden_cache` arguments we supported in our Transformer implementation to pass information between the modules."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "P5L7c5YifKd-"
      },
      "outputs": [],
      "source": [
        "#export\n",
        "class EncoderDecoder(nn.Module):\n",
        "    \"\"\"Encoder-Decoder Model which combines the two architectures\"\"\"\n",
        "    def __init__(self, encoder_config, decoder_config):\n",
        "        super().__init__()\n",
        "        # Add end of sequence token.\n",
        "        decoder_config.vocab_size += 1\n",
        "        self.vocab_size = decoder_config.vocab_size\n",
        "        self.encoder = Encoder(encoder_config)\n",
        "        self.decoder = Decoder(decoder_config)\n",
        "\n",
        "    def configure_optimizers(self, train_config):\n",
        "        enc_groups = self.encoder.configure_optimizers(train_config)\n",
        "        dec_groups = self.decoder.configure_optimizers(train_config)\n",
        "        return enc_groups + dec_groups\n",
        "\n",
        "    def forward(self, prefix, targets=None):\n",
        "        \"\"\"\n",
        "        :param prefix: int Tensor of shape (B,P_T)\n",
        "        :param idx: float Tensor of shape (B,P_T,n_embd)\n",
        "        :returns logits: float Tensor of shape (B, vocab_size)\n",
        "        :returns loss: float Tensor of shape (B) or None\n",
        "        \"\"\"\n",
        "        B = prefix.shape[0]\n",
        "        idx = torch.tensor([[]]).repeat(B, 1)\n",
        "        if targets is not None:\n",
        "          idx = torch.cat((idx, targets), dim=1)\n",
        "\n",
        "        ##############################################################################\n",
        "        # TODO:                                                                      #\n",
        "        # Create an Encoder Decoder Model by combining your previous transformers    #\n",
        "        # The Encoder should encode the tokens from prefix into an embeddings        #\n",
        "        # Use these in the hidden_cache to condition decoder generation              #\n",
        "        #                                                                            #\n",
        "        # This should be a 1-2 lines.                                                #\n",
        "        ##############################################################################\n",
        "        \n",
        "        # print(prefix)\n",
        "        hidden_cache = self.encoder.forward(prefix, return_hidden=True)\n",
        "        logits, loss = self.decoder.forward(idx, targets=targets, hidden_cache=hidden_cache)\n",
        "\n",
        "        ##############################################################################\n",
        "        #                               END OF YOUR CODE                             #\n",
        "        ##############################################################################\n",
        "        return logits, loss\n",
        "\n",
        "# #Do not change, it will break the AutoGrader\n",
        "# encdec_def = In[-1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wwTVJHeG4tVx"
      },
      "source": [
        "This will also require a custom `prefix_generation` function to account for the distinction between a human provided `prefix` and a model generated `idx` in the Encoder Decoder forward pass.\n",
        "\n",
        "Don't worry, this should be only a small change from your original `generate` function above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "0X8dl3D64uql"
      },
      "outputs": [],
      "source": [
        "#export\n",
        "def prefix_generate(model, prefix, max_new_tokens, temperature=1.0):\n",
        "    \"\"\"\n",
        "    :param prefix: int Tensor of shape (B, T)\n",
        "    :param max_new_tokens: int\n",
        "    :param temperature: Float\n",
        "    :returns idx: int Tensor of shape (B, max_new_tokens)\n",
        "    \"\"\"\n",
        "    idx = torch.tensor([[]], dtype=torch.long)\n",
        "    ##############################################################################\n",
        "    # TODO:                                                                      #\n",
        "    # Adjust your original generation function to work Encoder-Decoder models    #\n",
        "    #                                                                            #\n",
        "    # Note: This should be a one line change from the original generate function #\n",
        "    ##############################################################################\n",
        "\n",
        "    ### From Piazza: Pay close attention to the hint for prefix_generate function! \n",
        "    ## The starting prefix and starting idx are provided in the boilerplate code. \n",
        "    ## We mean \"small change\" quite literally - it should be at most 2 lines from the generate function if done correctly. \n",
        "    ## (There is complementary info in Piazza via image)\n",
        "    \n",
        "    ##############################################################################\n",
        "    #                               END OF YOUR CODE                             #\n",
        "    ##############################################################################\n",
        "    return idx\n",
        "\n",
        "# #Do not change, it will break the AutoGrader\n",
        "# pref_generate_def = In[-1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### End to End Test of Encoder Decoder Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "cellView": "form",
        "id": "kICaKJURf9-L"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "number of parameters: 0.09M\n",
            "number of parameters: 0.09M\n",
            "running on device cpu\n",
            "iter_dt 0.00ms; iter 0: train loss 1.44919\n",
            "iter_dt 22.42ms; iter 100: train loss 0.12494\n",
            "iter_dt 34.56ms; iter 200: train loss 0.02482\n",
            "iter_dt 26.71ms; iter 300: train loss 0.00422\n",
            "iter_dt 31.18ms; iter 400: train loss 0.01940\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "The size of tensor a (0) must match the size of tensor b (6) at non-singleton dimension 1",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[21], line 97\u001b[0m\n\u001b[1;32m     94\u001b[0m   model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m     95\u001b[0m   \u001b[38;5;28;01massert\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mallclose(prefix_generate(model, torch\u001b[38;5;241m.\u001b[39mtensor([[\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m]]), max_new_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m6\u001b[39m), torch\u001b[38;5;241m.\u001b[39mtensor([[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m]]))\n\u001b[0;32m---> 97\u001b[0m \u001b[43mtest_encoder_decoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSuccess with EncoderDecoder!!\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
            "Cell \u001b[0;32mIn[21], line 95\u001b[0m, in \u001b[0;36mtest_encoder_decoder\u001b[0;34m()\u001b[0m\n\u001b[1;32m     93\u001b[0m trainer\u001b[38;5;241m.\u001b[39mrun()\n\u001b[1;32m     94\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m---> 95\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mallclose\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprefix_generate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/anaconda3/envs/cs7643-a3/lib/python3.11/site-packages/torch/utils/_device.py:77\u001b[0m, in \u001b[0;36mDeviceContext.__torch_function__\u001b[0;34m(self, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m _device_constructors() \u001b[38;5;129;01mand\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     76\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\n\u001b[0;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (0) must match the size of tensor b (6) at non-singleton dimension 1"
          ]
        }
      ],
      "source": [
        "#@title End to End Test of Encoder Decoder Training\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "from gtgpt.trainer import Trainer\n",
        "\n",
        "import pickle\n",
        "\n",
        "class SortDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Dataset for the Sort problem. E.g. for problem length 6:\n",
        "    Input: 0 0 2 1 0 1 -> Output: 0 0 0 1 1 2\n",
        "    Which will feed into the transformer concatenated as:\n",
        "    input:  0 0 2 1 0 1 0 0 0 1 1\n",
        "    output: I I I I I 0 0 0 1 1 2\n",
        "    where I is \"ignore\", as the transformer is reading the input sequence\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, split, length=6, num_digits=3):\n",
        "        assert split in {'train', 'test'}\n",
        "        self.split = split\n",
        "        self.length = length\n",
        "        self.num_digits = num_digits\n",
        "\n",
        "    def __len__(self):\n",
        "        return 10000 # ...\n",
        "\n",
        "    def get_vocab_size(self):\n",
        "        return self.num_digits\n",
        "\n",
        "    def get_block_size(self):\n",
        "        # the length of the sequence that will feed into transformer,\n",
        "        # containing concatenated input and the output, but -1 because\n",
        "        # the transformer starts making predictions at the last input element\n",
        "        return 20\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        # use rejection sampling to generate an input example from the desired split\n",
        "        while True:\n",
        "            # generate some random integers\n",
        "            inp = torch.randint(self.num_digits, size=(self.length,), dtype=torch.long)\n",
        "            # half of the time let's try to boost the number of examples that\n",
        "            # have a large number of repeats, as this is what the model seems to struggle\n",
        "            # with later in training, and they are kind of rate\n",
        "            if torch.rand(1).item() < 0.5:\n",
        "                if inp.unique().nelement() > self.length // 2:\n",
        "                    # too many unqiue digits, re-sample\n",
        "                    continue\n",
        "            # figure out if this generated example is train or test based on its hash\n",
        "            h = hash(pickle.dumps(inp.tolist()))\n",
        "            inp_split = 'test' if h % 4 == 0 else 'train' # designate 25% of examples as test\n",
        "            if inp_split == self.split:\n",
        "                break # ok\n",
        "\n",
        "        # solve the task: i.e. sort\n",
        "        sol = torch.sort(inp)[0]\n",
        "\n",
        "        # concatenate the problem specification and the solution\n",
        "        cat = torch.cat((inp, sol), dim=0)\n",
        "\n",
        "        # the inputs to the transformer will be the offset sequence\n",
        "        x = cat[:self.length].clone()\n",
        "        y = cat[self.length:].clone()\n",
        "        # we only want to predict at output locations, mask out the loss at the input locations\n",
        "        return x, y\n",
        "\n",
        "def test_encoder_decoder():\n",
        "  # print an example instance of the dataset\n",
        "  train_dataset = SortDataset('train')\n",
        "  test_dataset = SortDataset('test')\n",
        "  x, y = train_dataset[0]\n",
        "  config = DummyTransformer.get_default_config()\n",
        "  config.vocab_size = train_dataset.get_vocab_size()\n",
        "  config.block_size = train_dataset.get_block_size()\n",
        "  config.n_layer = 3\n",
        "  config.n_embd = 48\n",
        "  config.n_head = 3\n",
        "  torch.set_default_device(\"cpu\")\n",
        "  set_seed(3407)\n",
        "  model = EncoderDecoder(config, config)\n",
        "  train_config = Trainer.get_default_config()\n",
        "  train_config.learning_rate = 5e-4 # the model we're using is so small that we can go a bit faster\n",
        "  train_config.max_iters = 500\n",
        "  train_config.num_workers = 0\n",
        "  train_config.device = \"cpu\"\n",
        "  trainer = Trainer(train_config, model, train_dataset)\n",
        "  def batch_end_callback(trainer):\n",
        "      if trainer.iter_num % 100 == 0:\n",
        "          print(f\"iter_dt {trainer.iter_dt * 1000:.2f}ms; iter {trainer.iter_num}: train loss {trainer.loss.item():.5f}\")\n",
        "  trainer.set_callback('on_batch_end', batch_end_callback)\n",
        "\n",
        "  trainer.run()\n",
        "  model.eval()\n",
        "  assert torch.allclose(prefix_generate(model, torch.tensor([[2, 1, 1, 0, 1, 2]]), max_new_tokens=6), torch.tensor([[0, 1, 1, 1, 2, 2]]))\n",
        "\n",
        "test_encoder_decoder()\n",
        "print('Success with EncoderDecoder!!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I3xuBrm4449O"
      },
      "source": [
        "# You've implemented a language model!\n",
        "\n",
        "## Now let's put it to use\n",
        "\n",
        "#### Language Modeling Setup (Do Not Change)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305,
          "referenced_widgets": [
            "7f433714991a4f909e267e96e5b0ad34",
            "83d8806be4f34aa799572e8e51906e53",
            "0fb02e83b1054e309ebd1a4e1b85c8f3",
            "5381dee1aa6744769b4ae857d99aa30e",
            "088f08cb071849d090a5581f8920b7b3",
            "84b55b8bb40443358303a787b1d6dd74",
            "b29e1f94da7a4f7a9f9c4e305d57134c",
            "0681d12069574084a1afde37591f2fb7",
            "bceadeca2d6b4e349868eebf40462c16",
            "1a4bdf9fa1794a00b68904bb43655ab5",
            "5d27e96d41454dac896c3e245062c14c",
            "da118269889144419a1bc00fad349320",
            "0b49267fdcd94f7dbb33c3047e53f5ad",
            "a2ebef0d5776446b95472010253ca706",
            "49e8e26d571d497d88ade012bb45c1d0",
            "5209561c1039425dbc2c30f8bfdcc8a3",
            "79dde3ea78f4477c94e2fea9c2b0a487",
            "a8d4b74977844f04ba4de0586d8f4343",
            "79a82d809f384952a9976faa36bbc983",
            "33f3e81ae3cb4a669773b1a6da0d5198",
            "3a5fdd4fa9ab428cb8cf3d0a39e6975c",
            "f665ac74f1ff4a4dbf5c9875160fa84c",
            "9fcb6551662042519a6a794104c77f0a",
            "c112146fb7d84adab11333eb4f89ec24",
            "222ea107180d423fa31f848cb9df9cd0",
            "2f5d3cb7e5224ecda85fd85ea3859dae",
            "1782bdeccbe4441bb69c4e1400ed5db9",
            "941afa9353944d05955c54861e75debe",
            "1202887cb19c4e91a316c275e60bf0e8",
            "577d66f264eb483b920d9fa50dbb1cd7",
            "b4c38b7a8b31454885c115782393aace",
            "f8c729b6d90145bc8b4af916062f2855",
            "33a31834bd3a4a6ca80cce6bcdd74b4f",
            "5d1c0690fcda4a7e946af973c041dfd0",
            "eadc04f9595b48a69b8b4636c690083c",
            "f7cc0bbdc0064b95972190aed2a9a68e",
            "73f415a1b6d0498385e2bcae36efd702",
            "91f22336015547799d147ad34a91ff53",
            "a40e21ea85484b27b2f139c6ea080e88",
            "f7e13c6a28964ee88cef374da44e7709",
            "c6edae2a5f97419d9873a828b34122de",
            "79be576dbb29430eb0da99de8dd7c330",
            "fd5e8bfe622343b99163aee1ae09e60a",
            "ce47c3c53cf04db79666b46a9a926959",
            "4d99081cc71743389203aac452f074b5",
            "e700a7b6bfec44849f3d9f22a9882897",
            "643dd7982f414454ad8d07a5e009a49e",
            "3e2832dac25948f5990a44200d4fc5a5",
            "ae82d74c83c445489dee0a74bf8bd913",
            "a453d95b99584301ba94773508aa3c44",
            "d761b54960e74f70aaee279bfeb37c57",
            "930fddfb385b43098ad9d1a44f7002c2",
            "72a5f372bf9d428a8865b2065a39db29",
            "2c375dcf9378423e8fc75faf72ab7a69",
            "314039618f0d44d29d6e5f31ced8bbee",
            "c2a7aaba23074c818c333469fe3cc9f9",
            "ce73b17791794fa2adcd176e8b3b0ccc",
            "234bc685641b4a7ebf16f436d7140ef9",
            "458962c76b4f43c6a58316b26bae96ae",
            "8daf97c336784b4893d230046e367c1f",
            "457723480aa64adca1b505179b08199f",
            "c5180598d9854669a5c609a7ea317c3d",
            "2385100246ea4b7d95c09e58b89a0ddf",
            "35c6c3abb5314d46af7d12236285e31f",
            "15eee2d2dde64e38a74096057d876339",
            "686d1f053daf4adaae6d76fcce46bc4c",
            "5a7e461ab78a48c7a1000735262c9e96",
            "6b3b38cfa73a4255b1568c6058130d89",
            "b7d86adba77f406fa06d6790f328f00b",
            "b021ea4cf6a44ed7b1052e94ddb1413f",
            "f49cae038ea34bb78c82f68c4838dd52",
            "83016f9db6e54642a9701461515209bd",
            "a23a8cc7d81a4f23955ca89e4465bd83",
            "98032da6685e4d3fb9b6208e4e9ee4f2",
            "e7d513434e9a4f02b8120a65ce0721e8",
            "5ad3b6bb02af41519a6be1d9df2bde35",
            "a0f111ade2bc440ba7deefca3a2a3423",
            "1ff341998bc340bf95f9266ff8d588ad",
            "325de401d74943aab1dae931a8b610a6",
            "4255dc7060994d2e892f35158f42d2bf",
            "677f11ac1bd54ae8bb6ec3873692d8a5",
            "96cffda114a9407e9c3f0ae331271797",
            "0f86badd062d4417bd8f685ccdfd2a52",
            "b3c1e5a1cf794f1bb160467aa3df772c",
            "38945e9952784919bb189b31a6ee91ae",
            "abc3cef5957f4e54bea4c11f76655d73",
            "d08c25723d9344daabffba590b8043e5",
            "819742506a484aafa79b6a6bf1833b2d",
            "8d4b4033ea274039a39df9e82eb384ea",
            "d12968ff526d45ae8c0911e1b101b595",
            "bf154a3b5f4545e898516814ffaa4a7a",
            "c1e76c710a6243bd99809b7247ab7eb1",
            "04ee5d4a744f450589b2c335d709b6fc",
            "dd1f887a608e4e9f887c124ef26d4f8b",
            "26782a58b6034e5d908f93ae8304b974",
            "6ffab46461ef4bc98729038aaa8abdcb",
            "1fc14bcfee094c579e446604c0fc3472",
            "b51d50422a6842d086b3cbff80e78f10",
            "5a0c43ce057b46b19b29646846a7d545"
          ]
        },
        "id": "W9XRRfet5CIL",
        "outputId": "d67c146d-fcf6-4e00-9c3d-82872a95ed38"
      },
      "outputs": [
        {
          "ename": "ImportError",
          "evalue": "cannot import name 'COMMON_SAFE_ASCII_CHARACTERS' from 'charset_normalizer.constant' (/home/anascimento7/anaconda3/envs/cs7643-a3/lib/python3.11/site-packages/charset_normalizer/constant.py)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "File \u001b[0;32m~/anaconda3/envs/cs7643-a3/lib/python3.11/site-packages/requests/compat.py:11\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 11\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mchardet\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'chardet'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[22], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtokenizers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrainers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m UnigramTrainer, BpeTrainer\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtokenizers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Unigram, BPE\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_dataset\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrandom\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mLMDataset\u001b[39;00m(Dataset):\n",
            "File \u001b[0;32m~/anaconda3/envs/cs7643-a3/lib/python3.11/site-packages/datasets/__init__.py:18\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# ruff: noqa\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Copyright 2020 The HuggingFace Datasets Authors and the TensorFlow Datasets Authors.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     16\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2.18.0\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marrow_dataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marrow_reader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ReadInstruction\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbuilder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ArrowBasedBuilder, BeamBasedBuilder, BuilderConfig, DatasetBuilder, GeneratorBasedBuilder\n",
            "File \u001b[0;32m~/anaconda3/envs/cs7643-a3/lib/python3.11/site-packages/datasets/arrow_dataset.py:62\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpyarrow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpa\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpyarrow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompute\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpc\u001b[39;00m\n\u001b[0;32m---> 62\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhuggingface_hub\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CommitInfo, CommitOperationAdd, CommitOperationDelete, DatasetCard, DatasetCardData, HfApi\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmultiprocess\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Pool\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcontrib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconcurrent\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m thread_map\n",
            "File \u001b[0;32m~/anaconda3/envs/cs7643-a3/lib/python3.11/site-packages/huggingface_hub/__init__.py:379\u001b[0m, in \u001b[0;36m_attach.<locals>.__getattr__\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m attr_to_modules:\n\u001b[1;32m    378\u001b[0m     submod_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpackage_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr_to_modules[name]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 379\u001b[0m     submod \u001b[38;5;241m=\u001b[39m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubmod_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    380\u001b[0m     attr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(submod, name)\n\u001b[1;32m    382\u001b[0m     \u001b[38;5;66;03m# If the attribute lives in a file (module) with the same\u001b[39;00m\n\u001b[1;32m    383\u001b[0m     \u001b[38;5;66;03m# name as the attribute, ensure that the attribute and *not*\u001b[39;00m\n\u001b[1;32m    384\u001b[0m     \u001b[38;5;66;03m# the module is accessible on the package.\u001b[39;00m\n",
            "File \u001b[0;32m~/anaconda3/envs/cs7643-a3/lib/python3.11/importlib/__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/anaconda3/envs/cs7643-a3/lib/python3.11/site-packages/huggingface_hub/hf_api.py:45\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     29\u001b[0m     Any,\n\u001b[1;32m     30\u001b[0m     BinaryIO,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     41\u001b[0m     overload,\n\u001b[1;32m     42\u001b[0m )\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01murllib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m quote\n\u001b[0;32m---> 45\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrequests\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrequests\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HTTPError\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mauto\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm \u001b[38;5;28;01mas\u001b[39;00m base_tqdm\n",
            "File \u001b[0;32m~/anaconda3/envs/cs7643-a3/lib/python3.11/site-packages/requests/__init__.py:45\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01murllib3\u001b[39;00m\n\u001b[0;32m---> 45\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RequestsDependencyWarning\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcharset_normalizer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__ \u001b[38;5;28;01mas\u001b[39;00m charset_normalizer_version\n",
            "File \u001b[0;32m~/anaconda3/envs/cs7643-a3/lib/python3.11/site-packages/requests/exceptions.py:9\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03mrequests.exceptions\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m~~~~~~~~~~~~~~~~~~~\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;03mThis module contains the set of Requests' exceptions.\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01murllib3\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m BaseHTTPError\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m JSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m CompatJSONDecodeError\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mRequestException\u001b[39;00m(\u001b[38;5;167;01mIOError\u001b[39;00m):\n\u001b[1;32m     13\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"There was an ambiguous exception that occurred while handling your\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;124;03m    request.\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
            "File \u001b[0;32m~/anaconda3/envs/cs7643-a3/lib/python3.11/site-packages/requests/compat.py:13\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mchardet\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[0;32m---> 13\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcharset_normalizer\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mchardet\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# -------\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Pythons\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# -------\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Syntax sugar.\u001b[39;00m\n",
            "File \u001b[0;32m~/anaconda3/envs/cs7643-a3/lib/python3.11/site-packages/charset_normalizer/__init__.py:23\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03mCharset-Normalizer\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m~~~~~~~~~~~~~~\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;124;03m:license: MIT, see LICENSE for more details.\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcharset_normalizer\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m from_fp, from_path, from_bytes, normalize\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcharset_normalizer\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlegacy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m detect\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcharset_normalizer\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__, VERSION\n",
            "File \u001b[0;32m~/anaconda3/envs/cs7643-a3/lib/python3.11/site-packages/charset_normalizer/api.py:10\u001b[0m\n\u001b[1;32m      7\u001b[0m     PathLike \u001b[38;5;241m=\u001b[39m Union[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mos.PathLike[str]\u001b[39m\u001b[38;5;124m'\u001b[39m]  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcharset_normalizer\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconstant\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TOO_SMALL_SEQUENCE, TOO_BIG_SEQUENCE, IANA_SUPPORTED\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcharset_normalizer\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmd\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mess_ratio\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcharset_normalizer\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CharsetMatches, CharsetMatch\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m warn\n",
            "File \u001b[0;32m~/anaconda3/envs/cs7643-a3/lib/python3.11/site-packages/charset_normalizer/md.py:5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Optional, List\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcharset_normalizer\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconstant\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m UNICODE_SECONDARY_RANGE_KEYWORD\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcharset_normalizer\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_punctuation, is_symbol, unicode_range, is_accentuated, is_latin, \\\n\u001b[1;32m      6\u001b[0m     remove_accent, is_separator, is_cjk, is_case_variable, is_hangul, is_katakana, is_hiragana, is_ascii, is_thai\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mMessDetectorPlugin\u001b[39;00m:\n\u001b[1;32m     10\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;124;03m    Base abstract class used for mess detection plugins.\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;124;03m    All detectors MUST extend and implement given methods.\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'COMMON_SAFE_ASCII_CHARACTERS' from 'charset_normalizer.constant' (/home/anascimento7/anaconda3/envs/cs7643-a3/lib/python3.11/site-packages/charset_normalizer/constant.py)"
          ]
        }
      ],
      "source": [
        "#@title Language Modeling Setup (Do Not Change)\n",
        "from gtgpt.trainer import Trainer\n",
        "from tqdm import tqdm\n",
        "from tokenizers import Tokenizer\n",
        "from tokenizers.pre_tokenizers import ByteLevel\n",
        "from tokenizers.trainers import UnigramTrainer, BpeTrainer\n",
        "from tokenizers.models import Unigram, BPE\n",
        "from datasets import load_dataset\n",
        "import random\n",
        "\n",
        "class LMDataset(Dataset):\n",
        "    def __init__(self, split, data, tokenizer, model):\n",
        "        assert split in {'train', 'test'}\n",
        "        self.model_type = \"EncDec\" if issubclass(type(model), EncoderDecoder) else \"Dec\"\n",
        "        if split == \"train\":\n",
        "          self.start_split = 0\n",
        "          self.end_split = 30000\n",
        "        else:\n",
        "          self.start_split = 30000\n",
        "          self.end_split = 40000\n",
        "        self.split = split\n",
        "        self.data = data\n",
        "        self.tokenizer = tokenizer\n",
        "        self.block_size = max([len(self.tokenizer.encode(inp)) for inp in self.data])\n",
        "        self.process()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data[self.start_split:self.end_split])\n",
        "\n",
        "    def get_vocab_size(self):\n",
        "        return self.tokenizer.get_vocab_size()\n",
        "\n",
        "    def get_block_size(self):\n",
        "        # the length of the sequence that will feed into transformer,\n",
        "        # containing concatenated input and the output, but -1 because\n",
        "        # the transformer starts making predictions at the last input element\n",
        "        return self.block_size\n",
        "\n",
        "    def process(self):\n",
        "      new_data = []\n",
        "      for inp in tqdm(self.data):\n",
        "        if self.model_type == \"EncDec\":\n",
        "          x_inp = inp.split(\"[SEP]\")[0] + \"[SEP]\"\n",
        "          y_inp = inp.split(\"[SEP]\")[1]\n",
        "          x = self.tokenizer.encode(x_inp)\n",
        "          y = self.tokenizer.encode(y_inp)\n",
        "        else:\n",
        "          x = self.tokenizer.encode(inp)\n",
        "          y = x[1:]\n",
        "          x = x[:-1]\n",
        "        x = x + ([-1] * (self.get_block_size() - len(x)))\n",
        "        y = y + ([-1] * (self.get_block_size() - len(y)))\n",
        "        new_data.append((x, y))\n",
        "      self.data = new_data\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "      x, y = self.data[self.start_split + idx]\n",
        "      return torch.tensor(x), torch.tensor(y)\n",
        "\n",
        "def format_review(row):\n",
        "  return {\"text\": f\"{row['translation']['eng']}[SEP]{row['translation']['engyay']}[END]\"}\n",
        "\n",
        "dataset = load_dataset(\"cdleong/piglatin-mt\")[\"train\"]\n",
        "data = [row[\"text\"] for row in dataset.map(format_review).to_list()]\n",
        "set_seed(3047)\n",
        "random.shuffle(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UcvP7ZXLEoq0"
      },
      "source": [
        "#### Training a Language Model from Scratch\n",
        "\n",
        "Above, we set up code which loads WikiHow articles as a training dataset either for pure Decoder models or with the Title passed as a prefix for an EncoderDecoder model. We want to train a model to translate between English and Pig-Latin!\n",
        "\n",
        "Below is an implementation which achieves between 40 and 50 percent accuracy. Modify the tokenizer, architecture, or hyperparameters to  decrease the loss as much as possible and drive accuracy above 80%. Report what you changed and your intuitions for why you changed it in the report powerpoint file and upload it as a PDF to GradeScope.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "SBbSkVLq5Eir"
      },
      "outputs": [],
      "source": [
        "# Incredibly Simplified Tokenizer so that you can manually hack it!\n",
        "# Feel free to add special tokens or modify as you wish.\n",
        "# For real world tokenizer usage, see https://huggingface.co/docs/tokenizers/\n",
        "class Tokenizer():\n",
        "  def __init__(self):\n",
        "    self.DELIM = \"|[DELIM]|\"\n",
        "    self.special_tokens = [\"[SEP]\", \"[END]\"]\n",
        "    self.special_tokens = [self.stringify(list(bytes(tok, \"utf-8\"))) for tok in self.special_tokens]\n",
        "    self.vocab_size = 256 + len(self.special_tokens)\n",
        "\n",
        "  def stringify(self, b_enc):\n",
        "    s_enc = [str(b) for b in b_enc]\n",
        "    return self.DELIM.join(s_enc)\n",
        "\n",
        "  def get_vocab_size(self):\n",
        "    return self.vocab_size\n",
        "\n",
        "  def encode(self, inp):\n",
        "    s_enc = self.stringify(list(bytes(inp, \"utf-8\")))\n",
        "    for i, tok in enumerate(self.special_tokens):\n",
        "      s_enc = s_enc.replace(tok, str(255+i+1))\n",
        "    return [int(s) for s in s_enc.split(self.DELIM)]\n",
        "\n",
        "  def decode(self, inp):\n",
        "    s_enc = self.stringify(inp)\n",
        "    for i, tok in enumerate(self.special_tokens):\n",
        "      s_enc = s_enc.replace(str(255+i+1), tok)\n",
        "    return  bytes([int(c) for c in s_enc.split(self.DELIM)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "5cfrrAkfDIQT"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "torch.set_default_device(DEVICE)\n",
        "def train(data, model_type=\"Decoder\",\n",
        "          learning_rate = 5e-4,\n",
        "          batch_size = 16,\n",
        "          max_iters = 10000,\n",
        "          dec_n_layer=1,\n",
        "          dec_n_embd=52,\n",
        "          dec_n_head = 1,\n",
        "          enc_n_layer=None,\n",
        "          enc_n_embd=None,\n",
        "          enc_n_head=None):\n",
        "  # Model Setup\n",
        "  tokenizer = Tokenizer()\n",
        "  dec_config = DummyTransformer.get_default_config()\n",
        "  dec_config.vocab_size = tokenizer.get_vocab_size()\n",
        "  dec_config.block_size = max([len(tokenizer.encode(inp)) for inp in data])\n",
        "  dec_config.n_layer = dec_n_layer\n",
        "  dec_config.n_embd = dec_n_embd\n",
        "  dec_config.n_head = dec_n_head\n",
        "  if model_type == \"Decoder\":\n",
        "    model = Decoder(dec_config)\n",
        "  else:\n",
        "    enc_config = DummyTransformer.get_default_config()\n",
        "    enc_config.vocab_size = tokenizer.get_vocab_size()\n",
        "    enc_config.block_size = max([len(tokenizer.encode(inp)) for inp in data])\n",
        "    enc_config.n_layer = enc_n_layer\n",
        "    enc_config.n_embd = enc_n_embd\n",
        "    enc_config.n_head = enc_n_head\n",
        "    model = EncoderDecoder(enc_config, dec_config)\n",
        "\n",
        "  # Training Config\n",
        "  train_config = Trainer.get_default_config()\n",
        "  train_config.learning_rate = learning_rate\n",
        "  train_config.max_iters = max_iters\n",
        "  train_config.batch_size = batch_size\n",
        "  train_config.num_workers = 0\n",
        "  train_config.device = DEVICE\n",
        "  train_ds = LMDataset(\"train\", data, tokenizer, model)\n",
        "  # Training Loop\n",
        "  trainer = Trainer(train_config, model, train_ds)\n",
        "  def batch_end_callback(trainer):\n",
        "      if trainer.iter_num % 100 == 0:\n",
        "          tqdm.write(f\"iter_dt {trainer.iter_dt * 1000:.2f}ms; iter {trainer.iter_num}: train loss {trainer.loss.item():.5f}\")\n",
        "          prefix = torch.tensor([tokenizer.encode(\"translate this to piglatin[SEP]\")])\n",
        "          if model_type == \"Decoder\":\n",
        "            output = generate(model, prefix, 100, 0.1)\n",
        "          else:\n",
        "            output = prefix_generate(model, prefix, 100, 0.1)\n",
        "          print(tokenizer.decode(output.cpu().numpy()[0]).split(bytes(\"[END]\", \"utf-8\"))[0])\n",
        "  trainer.set_callback('on_batch_end', batch_end_callback)\n",
        "  trainer.run()\n",
        "  return model, trainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "B7WzG16__KFU"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'data' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[27], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model, trainer \u001b[38;5;241m=\u001b[39m train(\u001b[43mdata\u001b[49m, model_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDecoder\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      2\u001b[0m           learning_rate \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5e-4\u001b[39m,\n\u001b[1;32m      3\u001b[0m           batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m16\u001b[39m,\n\u001b[1;32m      4\u001b[0m           max_iters \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10000\u001b[39m,\n\u001b[1;32m      5\u001b[0m           dec_n_layer\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m,\n\u001b[1;32m      6\u001b[0m           dec_n_embd\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m,\n\u001b[1;32m      7\u001b[0m           dec_n_head \u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m      8\u001b[0m           enc_n_layer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m      9\u001b[0m           enc_n_embd\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     10\u001b[0m           enc_n_head\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     11\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n",
            "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
          ]
        }
      ],
      "source": [
        "model, trainer = train(data, model_type=\"Decoder\",\n",
        "          learning_rate = 5e-4,\n",
        "          batch_size = 16,\n",
        "          max_iters = 10000,\n",
        "          dec_n_layer=4,\n",
        "          dec_n_embd=64,\n",
        "          dec_n_head =2,\n",
        "          enc_n_layer=None,\n",
        "          enc_n_embd=None,\n",
        "          enc_n_head=None)\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "LA77eMgfCsgA"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'trainer' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[28], line 28\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 28\u001b[0m   results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28meval\u001b[39m(\u001b[43mtrainer\u001b[49m, data, Tokenizer())\n",
            "\u001b[0;31mNameError\u001b[0m: name 'trainer' is not defined"
          ]
        }
      ],
      "source": [
        "from sacrebleu.metrics import BLEU\n",
        "\n",
        "def eval(trainer, data, tokenizer):\n",
        "    bleu = BLEU()\n",
        "    results = []\n",
        "    mistakes_printed_already = 0\n",
        "    tgts = []\n",
        "    cands = []\n",
        "    for sent in tqdm(data[10000:10100]):\n",
        "        inp = torch.tensor([tokenizer.encode(sent.split(\"[SEP]\")[0] + \"[SEP]\")])\n",
        "        tgt = bytes(sent.split(\"[SEP]\")[1].split(\"[END]\")[0], \"utf-8\")\n",
        "        cat = generate(model, inp, model.block_size-len(inp[0]), 0.1)\n",
        "        tgt_candidate = tokenizer.decode(cat.cpu().numpy()[0])\n",
        "        tgt_candidate = tgt_candidate.split(b\"[END]\")[0].split(b\"[SEP]\")[1]\n",
        "        # compare the predicted sequence to the true sequence\n",
        "        tgts.append([str(tgt)])\n",
        "        cands.append(str(tgt_candidate))\n",
        "        correct = (tgt == tgt_candidate)\n",
        "        results.append(correct)\n",
        "    results = torch.tensor(results).type(torch.float)\n",
        "    print(\"\\n\\nExact Match: %d/%d = %.2f%% correct\" % (torch.sum(results), len(results), 100*torch.mean(results)))\n",
        "    score = bleu.corpus_score(cands, tgts)\n",
        "    print(score)\n",
        "\n",
        "    return results\n",
        "\n",
        "with torch.no_grad():\n",
        "  results = eval(trainer, data, Tokenizer())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Assignment Export - Upload the my_llm_implementation.py file to GradeScope"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "1lWwrT4r3HGF",
        "outputId": "219b2b58-70a8-4f99-fef7-7e3d324a3555"
      },
      "source": [
        "#@title Assignment Export - Upload the `my_llm_implementation.py` file to GradeScope\n",
        "\n",
        "with open(\"./my_llm_implementation.py\", \"w\") as f:\n",
        "  f.write(setup_block.split(\"#Do not change, it will break the AutoGrader\")[0])\n",
        "  f.write(embedding_def.split(\"#Do not change, it will break the AutoGrader\")[0])\n",
        "  f.write(mha_def.split(\"#Do not change, it will break the AutoGrader\")[0])\n",
        "  f.write(block_def.split(\"#Do not change, it will break the AutoGrader\")[0])\n",
        "  f.write(transformer_def.split(\"#Do not change, it will break the AutoGrader\")[0])\n",
        "  f.write(encoder_def.split(\"#Do not change, it will break the AutoGrader\")[0])\n",
        "  f.write(decoder_def.split(\"#Do not change, it will break the AutoGrader\")[0])\n",
        "  f.write(generate_def.split(\"#Do not change, it will break the AutoGrader\")[0])\n",
        "  f.write(encdec_def.split(\"#Do not change, it will break the AutoGrader\")[0])\n",
        "  f.write(pref_generate_def.split(\"#Do not change, it will break the AutoGrader\")[0])\n",
        "\n",
        "# If you decide to do this assignment not on Colab, you'll need to simply find the file\n",
        "from google.colab import files\n",
        "files.download('./my_llm_implementation.py')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "UI5J9d5uMGgO"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Converted Transformer_Architectures.ipynb to my_llm_implementation.py\n"
          ]
        }
      ],
      "source": [
        "# If using VSCode in my repo:\n",
        "%run notebook2script submission"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "04ee5d4a744f450589b2c335d709b6fc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0681d12069574084a1afde37591f2fb7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "088f08cb071849d090a5581f8920b7b3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b49267fdcd94f7dbb33c3047e53f5ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_79dde3ea78f4477c94e2fea9c2b0a487",
            "placeholder": "",
            "style": "IPY_MODEL_a8d4b74977844f04ba4de0586d8f4343",
            "value": "Downloading readme: 100%"
          }
        },
        "0f86badd062d4417bd8f685ccdfd2a52": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0fb02e83b1054e309ebd1a4e1b85c8f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0681d12069574084a1afde37591f2fb7",
            "max": 5210,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bceadeca2d6b4e349868eebf40462c16",
            "value": 5210
          }
        },
        "1202887cb19c4e91a316c275e60bf0e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "15eee2d2dde64e38a74096057d876339": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1782bdeccbe4441bb69c4e1400ed5db9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a4bdf9fa1794a00b68904bb43655ab5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1fc14bcfee094c579e446604c0fc3472": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1ff341998bc340bf95f9266ff8d588ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_325de401d74943aab1dae931a8b610a6",
              "IPY_MODEL_4255dc7060994d2e892f35158f42d2bf",
              "IPY_MODEL_677f11ac1bd54ae8bb6ec3873692d8a5"
            ],
            "layout": "IPY_MODEL_96cffda114a9407e9c3f0ae331271797"
          }
        },
        "222ea107180d423fa31f848cb9df9cd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_577d66f264eb483b920d9fa50dbb1cd7",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b4c38b7a8b31454885c115782393aace",
            "value": 2
          }
        },
        "234bc685641b4a7ebf16f436d7140ef9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2385100246ea4b7d95c09e58b89a0ddf",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_35c6c3abb5314d46af7d12236285e31f",
            "value": 2
          }
        },
        "2385100246ea4b7d95c09e58b89a0ddf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26782a58b6034e5d908f93ae8304b974": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2c375dcf9378423e8fc75faf72ab7a69": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f5d3cb7e5224ecda85fd85ea3859dae": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f8c729b6d90145bc8b4af916062f2855",
            "placeholder": "",
            "style": "IPY_MODEL_33a31834bd3a4a6ca80cce6bcdd74b4f",
            "value": " 2/2 [00:03&lt;00:00,  1.40s/it]"
          }
        },
        "314039618f0d44d29d6e5f31ced8bbee": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "325de401d74943aab1dae931a8b610a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f86badd062d4417bd8f685ccdfd2a52",
            "placeholder": "",
            "style": "IPY_MODEL_b3c1e5a1cf794f1bb160467aa3df772c",
            "value": "Generating validation split: "
          }
        },
        "33a31834bd3a4a6ca80cce6bcdd74b4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "33f3e81ae3cb4a669773b1a6da0d5198": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "35c6c3abb5314d46af7d12236285e31f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "38945e9952784919bb189b31a6ee91ae": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "3a5fdd4fa9ab428cb8cf3d0a39e6975c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e2832dac25948f5990a44200d4fc5a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2c375dcf9378423e8fc75faf72ab7a69",
            "placeholder": "",
            "style": "IPY_MODEL_314039618f0d44d29d6e5f31ced8bbee",
            "value": " 188k/188k [00:00&lt;00:00, 5.89MB/s]"
          }
        },
        "4255dc7060994d2e892f35158f42d2bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_38945e9952784919bb189b31a6ee91ae",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_abc3cef5957f4e54bea4c11f76655d73",
            "value": 1
          }
        },
        "457723480aa64adca1b505179b08199f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "458962c76b4f43c6a58316b26bae96ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_15eee2d2dde64e38a74096057d876339",
            "placeholder": "",
            "style": "IPY_MODEL_686d1f053daf4adaae6d76fcce46bc4c",
            "value": " 2/2 [00:00&lt;00:00, 108.64it/s]"
          }
        },
        "49e8e26d571d497d88ade012bb45c1d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3a5fdd4fa9ab428cb8cf3d0a39e6975c",
            "placeholder": "",
            "style": "IPY_MODEL_f665ac74f1ff4a4dbf5c9875160fa84c",
            "value": " 1.34k/1.34k [00:00&lt;00:00, 85.1kB/s]"
          }
        },
        "4d99081cc71743389203aac452f074b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e700a7b6bfec44849f3d9f22a9882897",
              "IPY_MODEL_643dd7982f414454ad8d07a5e009a49e",
              "IPY_MODEL_3e2832dac25948f5990a44200d4fc5a5"
            ],
            "layout": "IPY_MODEL_ae82d74c83c445489dee0a74bf8bd913"
          }
        },
        "5209561c1039425dbc2c30f8bfdcc8a3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5381dee1aa6744769b4ae857d99aa30e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1a4bdf9fa1794a00b68904bb43655ab5",
            "placeholder": "",
            "style": "IPY_MODEL_5d27e96d41454dac896c3e245062c14c",
            "value": " 5.21k/5.21k [00:00&lt;00:00, 187kB/s]"
          }
        },
        "577d66f264eb483b920d9fa50dbb1cd7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a0c43ce057b46b19b29646846a7d545": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5a7e461ab78a48c7a1000735262c9e96": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6b3b38cfa73a4255b1568c6058130d89",
              "IPY_MODEL_b7d86adba77f406fa06d6790f328f00b",
              "IPY_MODEL_b021ea4cf6a44ed7b1052e94ddb1413f"
            ],
            "layout": "IPY_MODEL_f49cae038ea34bb78c82f68c4838dd52"
          }
        },
        "5ad3b6bb02af41519a6be1d9df2bde35": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d1c0690fcda4a7e946af973c041dfd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_eadc04f9595b48a69b8b4636c690083c",
              "IPY_MODEL_f7cc0bbdc0064b95972190aed2a9a68e",
              "IPY_MODEL_73f415a1b6d0498385e2bcae36efd702"
            ],
            "layout": "IPY_MODEL_91f22336015547799d147ad34a91ff53"
          }
        },
        "5d27e96d41454dac896c3e245062c14c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "643dd7982f414454ad8d07a5e009a49e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_930fddfb385b43098ad9d1a44f7002c2",
            "max": 188022,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_72a5f372bf9d428a8865b2065a39db29",
            "value": 188022
          }
        },
        "677f11ac1bd54ae8bb6ec3873692d8a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d08c25723d9344daabffba590b8043e5",
            "placeholder": "",
            "style": "IPY_MODEL_819742506a484aafa79b6a6bf1833b2d",
            "value": " 1000/0 [00:00&lt;00:00, 14140.14 examples/s]"
          }
        },
        "686d1f053daf4adaae6d76fcce46bc4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6b3b38cfa73a4255b1568c6058130d89": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_83016f9db6e54642a9701461515209bd",
            "placeholder": "",
            "style": "IPY_MODEL_a23a8cc7d81a4f23955ca89e4465bd83",
            "value": "Generating train split: "
          }
        },
        "6ffab46461ef4bc98729038aaa8abdcb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72a5f372bf9d428a8865b2065a39db29": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "73f415a1b6d0498385e2bcae36efd702": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd5e8bfe622343b99163aee1ae09e60a",
            "placeholder": "",
            "style": "IPY_MODEL_ce47c3c53cf04db79666b46a9a926959",
            "value": " 2.50M/2.50M [00:01&lt;00:00, 2.43MB/s]"
          }
        },
        "79a82d809f384952a9976faa36bbc983": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79be576dbb29430eb0da99de8dd7c330": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "79dde3ea78f4477c94e2fea9c2b0a487": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f433714991a4f909e267e96e5b0ad34": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_83d8806be4f34aa799572e8e51906e53",
              "IPY_MODEL_0fb02e83b1054e309ebd1a4e1b85c8f3",
              "IPY_MODEL_5381dee1aa6744769b4ae857d99aa30e"
            ],
            "layout": "IPY_MODEL_088f08cb071849d090a5581f8920b7b3"
          }
        },
        "819742506a484aafa79b6a6bf1833b2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "83016f9db6e54642a9701461515209bd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "83d8806be4f34aa799572e8e51906e53": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_84b55b8bb40443358303a787b1d6dd74",
            "placeholder": "",
            "style": "IPY_MODEL_b29e1f94da7a4f7a9f9c4e305d57134c",
            "value": "Downloading builder script: 100%"
          }
        },
        "84b55b8bb40443358303a787b1d6dd74": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d4b4033ea274039a39df9e82eb384ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d12968ff526d45ae8c0911e1b101b595",
              "IPY_MODEL_bf154a3b5f4545e898516814ffaa4a7a",
              "IPY_MODEL_c1e76c710a6243bd99809b7247ab7eb1"
            ],
            "layout": "IPY_MODEL_04ee5d4a744f450589b2c335d709b6fc"
          }
        },
        "8daf97c336784b4893d230046e367c1f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91f22336015547799d147ad34a91ff53": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "930fddfb385b43098ad9d1a44f7002c2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "941afa9353944d05955c54861e75debe": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96cffda114a9407e9c3f0ae331271797": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98032da6685e4d3fb9b6208e4e9ee4f2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "9fcb6551662042519a6a794104c77f0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c112146fb7d84adab11333eb4f89ec24",
              "IPY_MODEL_222ea107180d423fa31f848cb9df9cd0",
              "IPY_MODEL_2f5d3cb7e5224ecda85fd85ea3859dae"
            ],
            "layout": "IPY_MODEL_1782bdeccbe4441bb69c4e1400ed5db9"
          }
        },
        "a0f111ade2bc440ba7deefca3a2a3423": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a23a8cc7d81a4f23955ca89e4465bd83": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a2ebef0d5776446b95472010253ca706": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_79a82d809f384952a9976faa36bbc983",
            "max": 1336,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_33f3e81ae3cb4a669773b1a6da0d5198",
            "value": 1336
          }
        },
        "a40e21ea85484b27b2f139c6ea080e88": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a453d95b99584301ba94773508aa3c44": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8d4b74977844f04ba4de0586d8f4343": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "abc3cef5957f4e54bea4c11f76655d73": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ae82d74c83c445489dee0a74bf8bd913": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b021ea4cf6a44ed7b1052e94ddb1413f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5ad3b6bb02af41519a6be1d9df2bde35",
            "placeholder": "",
            "style": "IPY_MODEL_a0f111ade2bc440ba7deefca3a2a3423",
            "value": " 13232/0 [00:00&lt;00:00, 32186.50 examples/s]"
          }
        },
        "b29e1f94da7a4f7a9f9c4e305d57134c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b3c1e5a1cf794f1bb160467aa3df772c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b4c38b7a8b31454885c115782393aace": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b51d50422a6842d086b3cbff80e78f10": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7d86adba77f406fa06d6790f328f00b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_98032da6685e4d3fb9b6208e4e9ee4f2",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e7d513434e9a4f02b8120a65ce0721e8",
            "value": 1
          }
        },
        "bceadeca2d6b4e349868eebf40462c16": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bf154a3b5f4545e898516814ffaa4a7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ffab46461ef4bc98729038aaa8abdcb",
            "max": 13232,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1fc14bcfee094c579e446604c0fc3472",
            "value": 13232
          }
        },
        "c112146fb7d84adab11333eb4f89ec24": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_941afa9353944d05955c54861e75debe",
            "placeholder": "",
            "style": "IPY_MODEL_1202887cb19c4e91a316c275e60bf0e8",
            "value": "Downloading data files: 100%"
          }
        },
        "c1e76c710a6243bd99809b7247ab7eb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b51d50422a6842d086b3cbff80e78f10",
            "placeholder": "",
            "style": "IPY_MODEL_5a0c43ce057b46b19b29646846a7d545",
            "value": " 13232/13232 [00:00&lt;00:00, 24185.81 examples/s]"
          }
        },
        "c2a7aaba23074c818c333469fe3cc9f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ce73b17791794fa2adcd176e8b3b0ccc",
              "IPY_MODEL_234bc685641b4a7ebf16f436d7140ef9",
              "IPY_MODEL_458962c76b4f43c6a58316b26bae96ae"
            ],
            "layout": "IPY_MODEL_8daf97c336784b4893d230046e367c1f"
          }
        },
        "c5180598d9854669a5c609a7ea317c3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c6edae2a5f97419d9873a828b34122de": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce47c3c53cf04db79666b46a9a926959": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ce73b17791794fa2adcd176e8b3b0ccc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_457723480aa64adca1b505179b08199f",
            "placeholder": "",
            "style": "IPY_MODEL_c5180598d9854669a5c609a7ea317c3d",
            "value": "Extracting data files: 100%"
          }
        },
        "d08c25723d9344daabffba590b8043e5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d12968ff526d45ae8c0911e1b101b595": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dd1f887a608e4e9f887c124ef26d4f8b",
            "placeholder": "",
            "style": "IPY_MODEL_26782a58b6034e5d908f93ae8304b974",
            "value": "Map: 100%"
          }
        },
        "d761b54960e74f70aaee279bfeb37c57": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "da118269889144419a1bc00fad349320": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0b49267fdcd94f7dbb33c3047e53f5ad",
              "IPY_MODEL_a2ebef0d5776446b95472010253ca706",
              "IPY_MODEL_49e8e26d571d497d88ade012bb45c1d0"
            ],
            "layout": "IPY_MODEL_5209561c1039425dbc2c30f8bfdcc8a3"
          }
        },
        "dd1f887a608e4e9f887c124ef26d4f8b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e700a7b6bfec44849f3d9f22a9882897": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a453d95b99584301ba94773508aa3c44",
            "placeholder": "",
            "style": "IPY_MODEL_d761b54960e74f70aaee279bfeb37c57",
            "value": "Downloading data: 100%"
          }
        },
        "e7d513434e9a4f02b8120a65ce0721e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "eadc04f9595b48a69b8b4636c690083c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a40e21ea85484b27b2f139c6ea080e88",
            "placeholder": "",
            "style": "IPY_MODEL_f7e13c6a28964ee88cef374da44e7709",
            "value": "Downloading data: 100%"
          }
        },
        "f49cae038ea34bb78c82f68c4838dd52": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f665ac74f1ff4a4dbf5c9875160fa84c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f7cc0bbdc0064b95972190aed2a9a68e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c6edae2a5f97419d9873a828b34122de",
            "max": 2495681,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_79be576dbb29430eb0da99de8dd7c330",
            "value": 2495681
          }
        },
        "f7e13c6a28964ee88cef374da44e7709": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f8c729b6d90145bc8b4af916062f2855": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd5e8bfe622343b99163aee1ae09e60a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
